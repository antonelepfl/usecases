{"cells":[{"metadata":{},"cell_type":"markdown","source":["<font color='red'>**Note:** non-HBP members should contact “support@humanbrinproject.eu” for access to the validation tools</font>"]},{"metadata":{},"cell_type":"markdown","source":["## About this test\n","This test shall take as input a directory containing neuronal morphologies (currently supports `swc` format). The user decides whether to run the validations for all available morphologies, or a subset of these.\n","\n","The validations are carried out using 'NeuroM' (https://github.com/BlueBrain/NeuroM). The validation test evaluates the morphology in two stages:\n","\n","1. **Hard Constraints**\n","\n","   Here we evaluate the integrity of the neuronal reconstruction in order to determine if it is appropriate for further evaluations. The evaluations here can be sub-divided into the following NeuroM features (apps):\n","   \n","   - morph_check\n","   - cut_plane_detection <br /><br />\n","   \n","2. **Soft Constraints** [Currently only available for *Fast Spiking Interneurons*]\n","\n","     Neuronal reconstructions that pass the 'Hard Constraints' are evaluated here for their morphometric features. The features are extracted using NeuroM's morph_stats app, wherever possible, either directly or as a combination of multiple features. These are then compared against experimentally obtained data, as determined by the particular validation test being executed.\n","     \n","     Some of the features currently included are soma's diameter and the maximal branch order in the dendrites, besides the number of trunk sections, -X,Y,Z- extents, field's diameter and total path-length of both the axon and the dendrites.\n","     \n","     By the present, only FS interneurons can be considered, since observation data is missing for other neuron types."]},{"metadata":{},"cell_type":"markdown","source":["### Installing the required packages\n","(no user intervention required)"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["import os\n","import pkg_resources\n","from pkg_resources import parse_version\n","!pip install -q tornado==4.5.3"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<font color='red'>**Note:** If you encounter any errors in the below cell, please try to restart the kernel (Kernel -> Restart & Run All)</font>"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["req_packages = [    \n","                    {\"hbp_service_client\"       : {\"min_version\": \"1.1.0\",  \"install_version\": \"1.1.0\"}},\n","                    {\"sciunit\"                  : {\"min_version\": \"0.2.1\",  \"install_version\": \"0.2.1\"}},\n","                    {\"morphounit\"               : {\"min_version\": \"1.0.2\",  \"install_version\": \"1.0.2\"}},\n","                    {\"hbp_validation_framework\" : {\"min_version\": \"\", \"install_version\": \"https://github.com/appukuttan-shailesh/hbp-validation-client@usecase_patching\"}},\n","                    {\"neurom\"                   : {\"min_version\": \"1.4.10\", \"install_version\": \"1.4.10\"}},\n","                    {\"numpy\"                    : {\"min_version\": \"1.16.2\", \"install_version\": \"1.16.2\"}},    \n","                    {\"fpdf\"                     : {\"min_version\": \"1.7.2\",  \"install_version\": \"1.7.2\"}},\n","                    {\"PyPDF2\"                   : {\"min_version\": \"1.26.0\", \"install_version\": \"1.26.0\"}},\n","                    {\"tornado\"                  : {\"min_version\": \"4.5.3\",  \"install_version\": \"4.5.3\"}}\n","                ]\n","\n","def install_req_packages():\n","    # currently handles installations via PyPI and GitHub\n","    for pkg in req_packages:        \n","        for pkg_name, pkg_vinfo in pkg.items():\n","            print(\"Checking for package: {}\".format(pkg_name))        \n","            try:\n","                pkg_resources.get_distribution(pkg_name)        \n","                current_version = parse_version(pkg_resources.get_distribution(pkg_name).version)\n","                print(\"\\t{}: current version = {}\".format(pkg_name, current_version))\n","                if not pkg_vinfo[\"min_version\"] or current_version < parse_version(pkg_vinfo[\"min_version\"]) or current_version > parse_version(pkg_vinfo[\"install_version\"]):                                                \n","                        print(\"\\tInstalling another version of {}.\".format(pkg_name))\n","                        raise\n","            except:            \n","                if \"github.com\" in pkg_vinfo[\"install_version\"]:\n","                    os.system(\"pip install --quiet --no-cache-dir --force-reinstall git+{}\".format(pkg_vinfo[\"install_version\"]))\n","                else:\n","                    os.system(\"pip install --quiet --no-cache-dir --force-reinstall {}=={}\".format(pkg_name, pkg_vinfo[\"install_version\"]))                                \n","                print(\"\\t{}: installed version = {}\".format(pkg_name, pkg_vinfo[\"install_version\"]))\n","                if pkg_name == \"hbp_service_client\":\n","                    from IPython.display import HTML\n","                    display(HTML('''<script>window.requestAnimationFrame(() => { Jupyter.notebook.kernel.restart(); \\\n","                    Jupyter.notebook.dirty = false; window.location.reload(); })</script>'''))\n","\n","install_req_packages()                 "],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["import json\n","import urllib\n","import sciunit\n","import shutil\n","import pandas as pd\n","from pandas.io.json import json_normalize\n","from morphounit.utils import neuroM_loader, NeuroM_MorphStats \n","from hbp_validation_framework import utils, TestLibrary, ModelCatalog"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Check if Model Catalog and Validation Framework Apps Exist in Collab\n","If the notebook is run inside a Collab, we check if an instance of the Model Catalog and Validation Framework apps exist in the current Collab. If not, we add an instance of each (this will be reflected in the Collab's navigation panel, possibly on reloading the page).\n","\n","NOTE: **HBP_USERNAME** is an optional parameter when the notebook is being run inside the Collaboratory. The notebook can automatically identify your username in this scenario. This parameter needs to be specified if a user wishes to download the notebook and run it locally. Another potential (less likely) reason for specifying this (even within the Collaboratory) is in dealing with access permissions (wanting to run the test with different credentials).\n","\n","NOTE: Even if this notebook is not run inside a Collab, the following cell needs to be executed. It will identify if environment and manage accordingly. When not run inside a Collab, it will simply setup parameters required for the test, and not attempt to create new apps."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["# your HBP username; not essential if running inside the Collaboratory\n","HBP_USERNAME = \"\"\n","testLibrary = TestLibrary(username=HBP_USERNAME, environment=\"integration\")\n","modelCatalog = ModelCatalog.from_existing(testLibrary)\n","\n","try:\n","    collab_path = get_collab_storage_path()\n","    collab_id = collab_path[1:] # this might fail for very old Collabs which use name instead of Collab ID\n","except:\n","    # not run inside Collaboratory\n","    print(\"\\nPlease enter a Collab ID where you wish to store the results:\")\n","    print(\"E.g.: 8123\")\n","    print(\"Note: you should be a member of this Collab!\")\n","    collab_id = input()\n","    if not isinstance(collab_id, int):\n","        raise ValueError(\"Possibly invalid Collab ID: {}. Numeric input expected!\".format(collab_id))    \n","\n","# check if apps exist; if not then create them\n","MCapp_navID = modelCatalog.exists_in_collab_else_create(collab_id)\n","modelCatalog.set_app_config(collab_id=collab_id, app_id=MCapp_navID, only_if_new=\"True\")\n","VFapp_navID = testLibrary.exists_in_collab_else_create(collab_id)\n","testLibrary.set_app_config(collab_id=collab_id, app_id=VFapp_navID, only_if_new=\"True\")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Model Selection: Specifying model from ModelCatalog\n","The user is given an option to choose from existing compatible models."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["m1 = modelCatalog.get_model(model_id=\"f72f9e36-bb19-496a-8260-7090760319de\") # 2e196088-b39e-4975-a3bb-6dd6d52ddb3f\n","m2 = modelCatalog.get_model(model_id=\"53934bfe-2400-4ba5-852e-be4628d1998e\") # fee9a5eb-fbf1-4bb8-998c-992e3408fd3c\n","m3 = modelCatalog.get_model(model_id=\"e5b7b6dd-753c-4e09-999a-9c4e1c2e5177\") # 25f0ab7b-33a3-48db-8375-7e31dc385c22\n","list_of_models = [m1, m2, m3]\n","df = pd.DataFrame.from_dict(json_normalize(list_of_models), orient='columns')\n","df = df.reindex(['name', 'id', 'author', 'brain_region', 'species', 'cell_type', 'model_scope', 'abstraction_level', 'description'], axis=1)\n","df.index += 1 \n","print(\"Available models are listed below:\")\n","df.replace('\\n','', regex=True)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["print(\"Enter the # of required model: \")\n","choice = input()\n","if choice <= len(list_of_models) and choice > 0:   \n","    model_id = list_of_models[choice-1][\"id\"]\n","    model_name = list_of_models[choice-1][\"name\"]\n","else:\n","    raise ValueError(\"Invalid entry for model choice!\")"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"markdown","source":["### Gather Additional Info\n","Currently the test is applicable for three cell types: _D1-type MSN_, _D2-type MSN_ and _FS Interneurons_ <br />\n","The usecase tries to identify the cell type from the input directory. If this isn't possible, the user is prompted to specify the cell type."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["# will try to determine cell type from model name; if not then ask user\n","# current options: msn_d1, msn_d2, fs\n","cell_type_map = {\"msn_d1\" : \"medium spiny neuron (D1 type)\",\n","                 \"msn_d2\" : \"medium spiny neuron (D2 type)\",\n","                 \"fs\"     : \"fast spiking interneuron\"}\n","\n","if \"msn_d1\" in model_name:\n","    cell_type = \"msn_d1\" \n","elif \"msn_d2\" in model_name:\n","    cell_type = \"msn_d2\"\n","elif \"fs\" in model_name:\n","    cell_type = \"fs\"    \n","else:\n","    print(\"\\nPlease enter the cell_type: \")\n","    options = [\"msn_d1\", \"msn_d2\", \"fs\"]\n","    for i, each in enumerate(options,start=1):\n","        print(\"\\t{}. {}\".format(i,each))\n","    print(\"Enter the # of cell_type: \")\n","    choice = input()\n","    cell_type = options[choice-1]\n","print(\"Cell Type = {}\".format(cell_type))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Selection of desired model instance\n","The model has several model instances corresponding to various morphologies. These are listed below. The user needs to select one of these model instances."]},{"metadata":{"trusted":true,"scrolled":true,"collapsed":true},"cell_type":"code","source":["model_instances = modelCatalog.list_model_instances(model_id=model_id)\n","df = pd.DataFrame.from_dict(json_normalize(model_instances), orient='columns')\n","df = df.reindex(['version', 'id'], axis=1)\n","df.index += 1\n","pd.set_option('display.max_colwidth', -1)\n","df"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["The user is asked to specify the model instances that they are interested in validating. The valid range of values are indicated. The user can provide input as follows: <br />\n"," * All parameters, specify: `all` <br />\n"," * Single parameter set, specify number, e.g.: `1` <br />\n"," * Multiple parameter sets, specify numbers as a list, e.g.: `[1,4,5,8]` <br />"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["print(\"Enter the model instance(s) to be validated: 1 - {}\".format(len(model_instances)))\n","print(\"Example inputs: 1, 4, [1,4,5,8], all\")\n","instances_entry = raw_input().lower()\n","if instances_entry == \"all\":\n","    instances_list = range(1, len(model_instances)+1)\n","else:    \n","    if isinstance(eval(instances_entry), list):\n","        instances_list = eval(instances_entry)        \n","    elif isinstance(eval(instances_entry), int):\n","        instances_list = [eval(instances_entry)]\n","    else:\n","        raise ValueError(\"Invalid entry for parameter set!\")  \n","       \n","valid_instances_list = []\n","for i in instances_list:\n","    if i > 0 and i <= len(model_instances):\n","        valid_instances_list.append(i)\n","    else:\n","        print(\"Invalid entry: {}. Excluded.\".format(i))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Part 1: Hard Constraints Validation"]},{"metadata":{},"cell_type":"markdown","source":["### Instantiating the model; Running the validation tests\n","Validations for hard constraints are run for each of the selected morphologies. At the end of the test, the user is provided with a textual summary of the _score_ and the path to related output files generated by the test. These and other details can be viewed in the  _Validation Framework_ app (see Collab's Navigation panel; select `Validation Framework`)."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["result_uuids = []\n","\n","for index in valid_instances_list:\n","    model_instance_name = model_instances[index-1][\"version\"]    \n","    model_source = model_instances[index-1][\"source\"]\n","    model_path = os.path.abspath(urllib.urlretrieve(model_source, os.path.basename(model_source))[0])\n","    morph_model = neuroM_loader(model_path=model_path, name=model_instance_name)\n","    morph_model.model_uuid = model_id\n","    morph_model.model_version = model_instances[index-1][\"version\"]\n","       \n","    if cell_type in [\"msn_d1\", \"msn_d2\"]:\n","        test_alias = \"basalg_msn_morph_hardChecks\"\n","    else:\n","        test_alias = \"basalg_fs_morph_hardChecks\"\n","    result_id, score = utils.run_test(username=HBP_USERNAME, environment=\"integration\", model=morph_model, test_alias=test_alias, test_version=\"1.0\", storage_collab_id=collab_id, register_result=True, client_obj=testLibrary)\n","    result_uuids.append(result_id)    \n","\n","print(\"The result(s) can be viewed in the HBP Validation Framework app. Direct link(s):\")\n","for result_uuid in result_uuids:\n","    print(\"https://collab.humanbrainproject.eu/#/collab/{}/nav/{}?state=result.{}\".format(str(collab_id),str(VFapp_navID), result_uuid))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Score Summary"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["if len(result_uuids) > 0:\n","    df, excluded_results = utils.generate_score_matrix(environment=\"integration\", result_list=result_uuids, collab_id=collab_id, client_obj=modelCatalog)        \n","    from IPython.core.display import HTML\n","    HTML(\"<style>.rendered_html th {max-width: 120px;}</style>\")\n","    display(df)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Generate Report\n","The validation framework can generate a PDF report for all model variants (HoF parameter sets employed) that successfully completed the test. The user is prompted whether such a report should be generated for the current tests. If asked to generate, the location to the generated PDF is indicated."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["report_path = None\n","if len(result_uuids) > 0:\n","    print(\"\\nDo you wish to generate a report of the tests executed?\")\n","    print(\"Enter: y/n\")\n","    choice = raw_input().lower()\n","    valid_choices = {\"yes\": True, \"y\": True, \"no\": False, \"n\": False}\n","    if valid_choices[choice]:\n","        valid_uuids, report_path = utils.generate_report(environment=\"integration\", result_list=result_uuids, only_combined=True, client_obj=modelCatalog)    "],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### View Report Inside Jupyter Notebook\n","The PDF report created in the above cell is displayed within the Jupyter notebook. This can also be downloaded by clicking the download button inside the display frame."]},{"metadata":{"trusted":true,"scrolled":true,"collapsed":true},"cell_type":"code","source":["print report_path\n","if report_path:\n","    rel_report_path = os.path.relpath(report_path)\n","    from IPython.display import IFrame    \n","    display(IFrame(rel_report_path, width=900, height=650))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Part 2: Soft Constraints Validation\n","[Currently only available for Fast Spiking Interneurons]"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["if cell_type != \"fs\":\n","    print(\"Soft constraints validation not currently available for cell type = {}\".format(cell_type))\n","    result_uuids = []"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Instantiating the model; Running the validation tests\n","Validations for soft constraints are run for only the morphologies that _pass_ the first part of the test. At the end of the test, the user is provided with a textual summary of the _mean score_ value (across the features tested) and the path to related output files generated by the test. These and other details can be viewed in the  _Validation Framework_ app (see Collab's Navigation panel; select `Validation Framework`)."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["# Obtain instance_uuid of all above morphologies that passed the hard constraints validations\n","# Only these will be evaluated for the soft constraints\n","passed_morph_inst_uuid = []\n","for uuid in result_uuids:\n","    result = testLibrary.get_result(result_id=uuid)\n","    if result[\"results\"][0][\"passed\"]:\n","        passed_morph_inst_uuid.append(result[\"results\"][0][\"model_version_id\"])              \n","\n","models_path = '/tmp/neuroM_morph_softChecks'\n","if os.path.exists(models_path):\n","    shutil.rmtree(models_path)\n","os.makedirs(models_path)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["import morphounit.tests\n","\n","# Cycling through all above morphologies that passed the hard constraints validations\n","test_alias = 'morph_stats_Test'\n","\n","neuroM_stats_file = 'fs_cells_NeuroM_MorphStats_pred.json'\n","\n","result_uuids = []\n","\n","file_entries = os.listdir(models_path)\n","morph_files = [f for f in file_entries if f.endswith(\".swc\")]\n","\n","for uuid in passed_morph_inst_uuid:\n","    model_instance = modelCatalog.get_model_instance(instance_id=uuid)\n","    model_name = model_instance[\"version\"]\n","    model_source = model_instance[\"source\"]\n","    morph_path = os.path.abspath(urllib.urlretrieve(model_source, os.path.join(models_path, os.path.basename(model_source)))[0])\n","\n","    morph_model = NeuroM_MorphStats(model_name=model_name, morph_path=morph_path,\n","                                    neuroM_pred_file=neuroM_stats_file)\n","    \n","    print morph_path, \"---\", model_name, '\\n'\n","    \n","    morph_model.model_uuid = model_id          # uuid for the whole cell collection\n","    morph_model.model_version = model_name     # basename of each morphology file\n","\n","    result_id, score = utils.run_test(username=HBP_USERNAME, environment=\"integration\", \n","                               model=morph_model, test_alias=test_alias, test_version=\"2.0\",\n","                               storage_collab_id=collab_id, register_result=True, \n","                               client_obj=testLibrary)\n","\n","    result_uuids.append(result_id)\n","\n","if len(result_uuids) > 0:   \n","    print(\"The result(s) can be viewed in the HBP Validation Framework app. Direct link(s):\")\n","for result_uuid in result_uuids:\n","    print(\"https://collab.humanbrainproject.eu/#/collab/{}/nav/{}?state=result.{}\".format(str(collab_id),str(VFapp_navID), result_uuid))       "],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Score Summary"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["if len(result_uuids) > 0:\n","    df, excluded_results = utils.generate_score_matrix(environment=\"integration\", result_list=result_uuids, collab_id=collab_id, client_obj=modelCatalog)        \n","    from IPython.core.display import HTML\n","    HTML(\"<style>.rendered_html th {max-width: 120px;}</style>\")\n","    display(df)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Generate Report\n","The validation framework can generate a PDF report for all model variants that successfully completed the test. The user is prompted whether such a report should be generated for the current tests. If asked to generate, the location to the generated PDF is indicated."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["report_path = None\n","if len(result_uuids) > 0:\n","    print(\"\\nDo you wish to generate a report of the tests executed?\")\n","    print(\"Enter: y/n\")\n","    choice = raw_input().lower()\n","    valid_choices = {\"yes\": True, \"y\": True, \"no\": False, \"n\": False}\n","    if valid_choices[choice]:\n","        valid_uuids, report_path = utils.generate_report(environment=\"integration\", result_list=result_uuids, only_combined=True, client_obj=modelCatalog)    "],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### View Report Inside Jupyter Notebook\n","The PDF report created in the above cell is displayed within the Jupyter notebook. This can also be downloaded by clicking the download button inside the display frame."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["if report_path:\n","    rel_report_path = os.path.relpath(report_path)\n","    from IPython.display import IFrame    \n","    display(IFrame(rel_report_path, width=900, height=650))"],"execution_count":null,"outputs":[]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"name":"python2","display_name":"Python 2","language":"python"},"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","name":"python","pygments_lexer":"ipython2","version":"2.7.15","file_extension":".py","codemirror_mode":{"version":2,"name":"ipython"}}},"nbformat":4,"nbformat_minor":2}