{"cells":[{"metadata":{},"cell_type":"markdown","source":["<font color='red'>**Note:** non-HBP members should contact “support@humanbrinproject.eu” for access to the validation tools</font>"]},{"metadata":{},"cell_type":"markdown","source":["## About this test\n","This test shall take as input a BluePyOpt optimized output file. The validation test would then evaluate the model for all parameter sets against various eFEL features. It should be noted that the reference data used is that located within the model, so this test can be considered as a quantification of the goodness of fitting the model. The results are registered on the HBP Validation Framework app. If an instance of the Model Catalog and Validation Framework are not found in the current Collab, then these are created. Additionally, a test report is generated and this can be viewed within the Jupyter notebook, or downloaded."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["import os\n","import pkg_resources\n","from pkg_resources import parse_version\n","!pip install -q tornado==4.5.3"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<font color='red'>**Note:** If you encounter any errors in the below cell, please try to restart the kernel (Kernel -> Restart & Run All)</font>"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["req_packages = [    \n","                    {\"hbp_service_client\"       : {\"min_version\": \"1.1.0\",  \"install_version\": \"1.1.0\"}},\n","                    {\"sciunit\"                  : {\"min_version\": \"0.2.1\",  \"install_version\": \"0.2.1\"}},\n","                    {\"neuronunit\"               : {\"min_version\": \"0.1.8.2\",\"install_version\": \"0.1.8.2\"}},\n","                    {\"eFELunit\"                 : {\"min_version\": \"1.1.4\",  \"install_version\": \"1.1.4\"}},\n","                    {\"bluepyopt\"                : {\"min_version\": \"1.6.22\", \"install_version\": \"1.6.42\"}},                    \n","                    {\"hbp_validation_framework\" : {\"min_version\": \"\", \"install_version\": \"https://github.com/appukuttan-shailesh/hbp-validation-client@usecase_patching\"}},\n","                    {\"numpy\"                    : {\"min_version\": \"1.16.2\", \"install_version\": \"1.16.2\"}},    \n","                    {\"neo\"                      : {\"min_version\": \"0.6.1\",  \"install_version\": \"0.6.1\"}},\n","                    {\"fpdf\"                     : {\"min_version\": \"1.7.2\",  \"install_version\": \"1.7.2\"}},\n","                    {\"PyPDF2\"                   : {\"min_version\": \"1.26.0\", \"install_version\": \"1.26.0\"}},\n","                    {\"tornado\"                  : {\"min_version\": \"4.5.3\",  \"install_version\": \"4.5.3\"}}\n","                ]\n","\n","def install_req_packages():\n","    # currently handles installations via PyPI and GitHub\n","    for pkg in req_packages:        \n","        for pkg_name, pkg_vinfo in pkg.items():\n","            print(\"Checking for package: {}\".format(pkg_name))        \n","            try:\n","                pkg_resources.get_distribution(pkg_name)        \n","                current_version = parse_version(pkg_resources.get_distribution(pkg_name).version)\n","                print(\"\\t{}: current version = {}\".format(pkg_name, current_version))\n","                if not pkg_vinfo[\"min_version\"] or current_version < parse_version(pkg_vinfo[\"min_version\"]) or current_version > parse_version(pkg_vinfo[\"install_version\"]):                                                \n","                        print(\"\\tInstalling another version of {}.\".format(pkg_name))\n","                        raise\n","            except:            \n","                if \"github.com\" in pkg_vinfo[\"install_version\"]:\n","                    os.system(\"pip install --quiet --no-cache-dir --force-reinstall git+{}\".format(pkg_vinfo[\"install_version\"]))\n","                else:\n","                    os.system(\"pip install --quiet --no-cache-dir --force-reinstall {}=={}\".format(pkg_name, pkg_vinfo[\"install_version\"]))                                \n","                print(\"\\t{}: installed version = {}\".format(pkg_name, pkg_vinfo[\"install_version\"]))\n","                if pkg_name == \"hbp_service_client\":\n","                    from IPython.display import HTML\n","                    display(HTML('''<script>window.requestAnimationFrame(() => { Jupyter.notebook.kernel.restart(); \\\n","                    Jupyter.notebook.dirty = false; window.location.reload(); })</script>'''))\n","\n","install_req_packages()                 "],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["import sciunit\n","import bluepyopt.ephys as ephys\n","from eFELunit.utils import CellModel\n","from hbp_validation_framework import utils, TestLibrary, ModelCatalog\n","\n","import json\n","import requests\n","import urllib2\n","import StringIO\n","import zipfile\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import pandas as pd\n","from pandas.io.json import json_normalize"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Check if Model Catalog and Validation Framework Apps Exist in Collab\n","If the notebook is run inside a Collab, we check if an instance of the Model Catalog and Validation Framework apps exist in the current Collab. If not, we add an instance of each (this will be reflected in the Collab's navigation panel, possibly on reloading the page).\n","\n","NOTE: **HBP_USERNAME** is an optional parameter when the notebook is being run inside the Collaboratory. The notebook can automatically identify your username in this scenario. This parameter needs to be specified if a user wishes to download the notebook and run it locally. Another potential (less likely) reason for specifying this (even within the Collaboratory) is in dealing with access permissions (wanting to run the test with different credentials).\n","\n","NOTE: Even if this notebook is not run inside a Collab, the following cell needs to be executed. It will identify if environment and manage accordingly. When not run inside a Collab, it will simply setup parameters required for the test, and not attempt to create new apps."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["# your HBP username; not essential if running inside the Collaboratory\n","HBP_USERNAME = \"\"\n","testLibrary = TestLibrary(username=HBP_USERNAME, environment=\"integration\")\n","modelCatalog = ModelCatalog.from_existing(testLibrary)\n","\n","try:\n","    collab_path = get_collab_storage_path()\n","    collab_id = collab_path[1:] # this might fail for very old Collabs which use name instead of Collab ID\n","except:\n","    # not run inside Collaboratory\n","    print(\"\\nPlease enter a Collab ID where you wish to store the results:\")\n","    print(\"E.g.: 8123\")\n","    print(\"Note: you should be a member of this Collab!\")\n","    collab_id = input()\n","    if not isinstance(collab_id, int):\n","        raise ValueError(\"Possibly invalid Collab ID: {}. Numeric input expected!\".format(collab_id))    \n","\n","# check if apps exist; if not then create them\n","MCapp_navID = modelCatalog.exists_in_collab_else_create(collab_id)\n","modelCatalog.set_app_config(collab_id=collab_id, app_id=MCapp_navID, only_if_new=\"True\")\n","VFapp_navID = testLibrary.exists_in_collab_else_create(collab_id)\n","testLibrary.set_app_config(collab_id=collab_id, app_id=VFapp_navID, only_if_new=\"True\")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Model Selection: Specifying model from ModelCatalog\n","Hippocampus models registered on the Model Catalog and known to be in the BluePyOpt format are listed below."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["l1 = modelCatalog.list_models(brain_region=\"hippocampus\", collab_id=\"12027\")#, author=\"Rosanna Migliore\")\n","l2 = modelCatalog.list_models(brain_region=\"hippocampus\", collab_id=\"9821\")#, author=\"Rosanna Migliore\")\n","# l3 = modelCatalog.list_models(brain_region=\"hippocampus\", collab_id=\"12027\", author=\"Paola Vitale\")\n","# l4 = modelCatalog.list_models(brain_region=\"hippocampus\", collab_id=\"9821\", author=\"Paola Vitale\")\n","list_of_models = []\n","list_of_models.extend(l1)\n","list_of_models.extend(l2)\n","# list_of_models.extend(l3)\n","# list_of_models.extend(l4)\n","for item in list_of_models:\n","    if item[\"author\"][0][\"family_name\"] not in [\"Migliore\", \"Vitale\"]:\n","        list_of_models.remove(item)\n","print len(list_of_models) \n","df = pd.DataFrame.from_dict(json_normalize(list_of_models), orient='columns')\n","df = df.reindex(['name', 'id', 'author', 'brain_region', 'species', 'cell_type', 'model_scope', 'abstraction_level', 'description'], axis=1)\n","df.index += 1\n","df"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"collapsed":true},"cell_type":"code","source":["print(\"\\nEnter the # of required model: \")\n","choice = input()\n","if choice <= len(list_of_models) and choice > 0:\n","    model_id = list_of_models[choice-1][\"id\"]\n","    model_name = list_of_models[choice-1][\"name\"]\n","    model_instances = modelCatalog.list_model_instances(model_id=model_id)    \n","    model_instance_json = max(model_instances, key=lambda x:x['timestamp'])\n","    file_path = model_instance_json[\"source\"]\n","else:\n","    raise ValueError(\"Invalid entry for model choice!\")\n","\n","try:        \n","    response = requests.get(file_path)\n","    zip_ref = zipfile.ZipFile(StringIO.StringIO(response.content))\n","    zip_ref.extractall()\n","    model_path = os.path.join(os.getcwd(),model_name)\n","\n","    meta_info = requests.get(file_path.replace(\".zip\", \"_meta.json\"))    \n","    if meta_info.status_code == 200:\n","        with open(os.path.join(model_path, model_name+\"_meta.json\"), 'w') as f:\n","            json.dump(meta_info.json(), f)\n","    \n","    model_image_url = file_path.replace(model_name+\".zip\", \"_\".join(model_name.split(\"_\")[3:-1])+\"_morph.jpeg\")\n","    model_image = requests.get(model_image_url)    \n","    model_image_localPath = None\n","    if model_image.status_code == 200:        \n","        model_image_localPath = os.path.join(model_path, model_name.split(\"_\")[3]+\"_morph.jpg\")\n","        with open(model_image_localPath, 'wb') as f:\n","            f.write(model_image.content)         \n","        print \"\\nModel Morphology:\"\n","        img = mpimg.imread(model_image_localPath)\n","        imgplot = plt.imshow(img)\n","        plt.show()\n","except:\n","    raise IOError(\"Model url = {} is invalid!\".format(file_path))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":[" ### Instantiating the model; Running validation\n","The usecase will run validations on the specified model. At the end of the test, the user is provided with a textual summary of the score and the path to related output files generated by the test. These and other details can be viewed in the Validation Framework app (see Collab's Navigation panel; select Validation Framework)."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["cell_model = CellModel(model_path=model_path, model_name=model_name, run_alerts=True)\n","cell_model.model_uuid = model_id\n","cell_model.source = file_path\n","cell_model.model_version = \"1.0\"\n","\n","result_uuid, score = utils.run_test(username=HBP_USERNAME, environment=\"integration\", model=cell_model, test_alias=\"bpo_efel\", test_version=\"1.0\", storage_collab_id=collab_id, register_result=True, client_obj=testLibrary, observation_dir=cell_model.base_path, plot_figure=True)\n","\n","print(\"The result(s) can be viewed in the HBP Validation Framework app. Direct link:\")\n","print(\"https://collab.humanbrainproject.eu/#/collab/{}/nav/{}?state=result.{}\".format(str(collab_id),str(VFapp_navID), result_uuid))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Score Summary"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["if result_uuid:    \n","    df, excluded_results = utils.generate_score_matrix(environment=\"integration\", result_list=[result_uuid], collab_id=collab_id, client_obj=modelCatalog)        \n","    from IPython.core.display import HTML\n","    HTML(\"<style>.rendered_html th {max-width: 120px;}</style>\")\n","    display(df)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### Generate Report\n","The validation framework can generate a PDF report for a successfully completed test. The user is prompted whether such a report should be generated for the current tests. If asked to generate, the location to the generated PDF is indicated."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["report_path = None\n","if result_uuid:\n","    print(\"\\nDo you wish to generate a report of the tests executed?\")\n","    print(\"Enter: y/n\")\n","    choice = raw_input().lower()\n","    valid_choices = {\"yes\": True, \"y\": True, \"no\": False, \"n\": False}\n","    if valid_choices[choice]:\n","        valid_uuids, report_path = utils.generate_report(environment=\"integration\", result_list=[result_uuid], only_combined=True, client_obj=modelCatalog)    "],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### View Report Inside Jupyter Notebook\n","The PDF report created in the above cell is displayed within the Jupyter notebook. This can also be downloaded by clicking the download button inside the display frame."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["print report_path\n","if report_path:\n","    rel_report_path = os.path.relpath(report_path)\n","    from IPython.display import IFrame    \n","    display(IFrame(rel_report_path, width=900, height=650))"],"execution_count":null,"outputs":[]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"name":"python2","display_name":"Python 2","language":"python"},"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","name":"python","pygments_lexer":"ipython2","version":"2.7.15","file_extension":".py","codemirror_mode":{"version":2,"name":"ipython"}}},"nbformat":4,"nbformat_minor":2}