{"cells":[{"metadata":{},"cell_type":"markdown","source":["<div class=\"alert alert-block alert-warning\">\n","Only Python 3 compatible! Python 2 support has been dropped since v3.0 of this UseCase.\n","</div>"]},{"metadata":{},"cell_type":"markdown","source":["# Validation Framework Demonstration Use Case\n","***\n","**Aim: ** To demonstrate the working of the HBP Validation Framework via validating a cerebellar Purkinje cell model against experimental data\n","\n","***\n","**Version:** 3.1 (13/01/2020)\n","***\n","**Contributors:**  Shailesh Appukuttan (CNRS), Andrew Davison (CNRS), Lungsi Sharma (CNRS)\n","***\n","**Contact:** [shailesh.appukuttan@unic.cnrs-gif.fr](mailto:shailesh.appukuttan@unic.cnrs-gif.fr)"]},{"metadata":{"collapsed":true},"cell_type":"markdown","source":["<div class=\"alert alert-block alert-success\" style=\"color:black\">\n","<h2>About This Use Case</h2><br />\n","In this demo, you will download a published NEURON model of a Purkinje cell, run several different simulation experiments, and compare the results against experimental data.\n","\n","The demo has several sections:\n","<ol>\n","<li>Install software</li>\n","<li>Download the model</li>\n","<li>Check if _'Model Catalog'_ and _'Validation Framework'_ apps exist in Collab</li>\n","<li>Get information about the model from the HBP Model Catalog</li>\n","<li>View available tests and select one of the tests</li>\n","<li>Download and run the validation test</li>\n","<li>Inspect the result of the validation test</li>\n","</ol>\n","<br />\n","To run the demo, execute each of the notebook cells in order."]},{"metadata":{},"cell_type":"markdown","source":["## 1. Install software\n","(no user intervention required)"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["#Loading the proper version of NEURON\n","!ln -sfn /home/jovyan/.local/nrn-7.6/ /home/jovyan/.local/nrn"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true},"cell_type":"code","source":["%matplotlib inline\n","from IPython.display import Markdown as markdown\n","import os\n","import pkg_resources\n","from pkg_resources import parse_version\n","!pip install -q tornado==4.5.3\n","!pip install -q --upgrade hbp-service-client"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<div class=\"alert alert-block alert-danger\">\n","<strong>Note:</strong> If you encounter any errors in the below cell, please try to restart the kernel (Kernel -> Restart & Run All)\n","</div>"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["req_packages = [    \n","                    {\"sciunit\"                  : {\"min_version\": \"0.2.1\",  \"install_version\": \"0.2.1\"}},\n","                    {\"hbp_validation_framework\" : {\"min_version\": \"0.5.28\", \"install_version\": \"0.5.28\"}},\n","                    {\"numpy\"                    : {\"min_version\": \"1.16.2\", \"install_version\": \"1.16.2\"}},    \n","                    {\"Jinja2\"                   : {\"min_version\": \"2.10.3\", \"install_version\": \"2.10.3\"}},\n","                    {\"neo\"                      : {\"min_version\": \"0.5.2\",  \"install_version\": \"0.5.2\"}},\n","                    {\"elephant\"                 : {\"min_version\": \"0.4.3\",  \"install_version\": \"0.4.3\"}},\n","                    {\"tornado\"                  : {\"min_version\": \"4.5.3\",  \"install_version\": \"4.5.3\"}}    \n","                ]\n","\n","def install_req_packages():\n","    # currently handles installations via PyPI and GitHub\n","    for pkg in req_packages:        \n","        for pkg_name, pkg_vinfo in pkg.items():\n","            print(\"Checking for package: {}\".format(pkg_name))        \n","            try:\n","                pkg_resources.get_distribution(pkg_name)        \n","                current_version = parse_version(pkg_resources.get_distribution(pkg_name).version)\n","                print(\"\\t{}: current version = {}\".format(pkg_name, current_version))\n","                if not pkg_vinfo[\"min_version\"] or current_version < parse_version(pkg_vinfo[\"min_version\"]) or current_version > parse_version(pkg_vinfo[\"install_version\"]):                                                \n","                        print(\"\\tInstalling another version of {}.\".format(pkg_name))\n","                        raise\n","            except:            \n","                if \"github.com\" in pkg_vinfo[\"install_version\"]:\n","                    os.system(\"pip install --quiet --no-cache-dir --force-reinstall git+{}\".format(pkg_vinfo[\"install_version\"]))\n","                else:\n","                    os.system(\"pip install --quiet --no-cache-dir --force-reinstall {}=={}\".format(pkg_name, pkg_vinfo[\"install_version\"]))                                \n","                print(\"\\t{}: installed version = {}\".format(pkg_name, pkg_vinfo[\"install_version\"]))\n","\n","install_req_packages()                 "],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["import sciunit\n","from hbp_validation_framework import utils, TestLibrary, ModelCatalog\n","import pandas as pd\n","from pandas.io.json import json_normalize"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true},"cell_type":"code","source":["%%capture \n","!pip install -U --no-cache-dir git+https://github.com/appukuttan-shailesh/cerebellum-unit.git"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 2. Download the model\n","\n","The model is stored in a repository on Github. Here we will use Git to get a copy of the repository."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["%%bash\n","if [ ! -d \"hbp-cerebellum-models\" ] ; then\n","    # if this is the first time running this notebook, clone the Git repository\n","    git clone https://github.com/appukuttan-shailesh/hbp-cerebellum-models\n","    cd hbp-cerebellum-models\n","    git fetch\n","else\n","    # otherwise pull any recent changes\n","    cd hbp-cerebellum-models\n","    git pull\n","fi"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["cd hbp-cerebellum-models"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.1 Create an instance of the Purkinje cell model"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["from models import cells\n","pc = cells.PC2015Masoli.PurkinjeCell()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 2.2 Run sample simulations\n","This part is not necessary for validating the model, but let's run a simulation to get an idea of how the model behaves:"]},{"metadata":{},"cell_type":"markdown","source":["#### 2.2.1 ... without current injection (model fires spontaneously)"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["pc.set_simulation_properties({\"dt\": 0.025,\n","                             \"celsius\": 37,\n","                             \"v_init\": -60,\n","                             \"tstop\": 200})\n","pc.produce_voltage_response()  # this runs the simulation, it may take a couple of minutes"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["from models import plot_manager as pm\n","pm.visualize_voltages(model_name=\"PC2015Masoli\", region_of_interest=\"vm_soma\")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["#### 2.2.2 ... with external current injection"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["pc.set_simulation_properties({\"dt\": 0.025,\n","                             \"celsius\": 37,\n","                             \"v_init\": -60,\n","                             \"tstop\": 200})\n","# set current injection stimulus\n","stimuli = pc.set_stimulation_properties({\"current1\": {\"amp\": 0.5, \"dur\": 100, \"delay\": 50}})\n","pc.produce_voltage_response()  # this runs the simulation, it may take a couple of minutes\n","\n","# remove the current injection to avoid interference with subsequent simulations\n","stimuli = pc.set_stimulation_properties({})"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["pm.visualize_voltages(model_name=\"PC2015Masoli\", region_of_interest=\"vm_soma\")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 3. Check if 'Model Catalog' and 'Validation Framework' apps exist in Collab\n","The HBP Model Catalog contains information about models of many kinds, from detailed biophysical models to abstract conceptual models, from models of sub-cellular mechanisms to models of entire brain regions. The HBP Validation Service lets us keep track of all the validation tests that have been run for these different models.\n","\n","Just as the Model Catalog holds information about models, the Validation Test Library holds information about validation tests. You can access the validation test library using a graphical app, or using the Python client. For more information, see the [documentation](http://hbp-validation-client.readthedocs.io/)."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["test_library = TestLibrary()\n","catalog = ModelCatalog.from_existing(test_library)\n","\n","try:\n","    collab_path = get_collab_storage_path()\n","    collab_id = collab_path[1:] # this might fail for very old Collabs which use name instead of Collab ID\n","except:\n","    # not run inside Collaboratory\n","    print(\"\\nPlease enter a Collab ID where you wish to store the results:\")\n","    print(\"E.g.: 8123\")\n","    print(\"Note: you should be a member of this Collab!\")\n","    collab_id = input()\n","    if not isinstance(collab_id.isdigit()):\n","        raise ValueError(\"Possibly invalid Collab ID: {}. Numeric input expected!\".format(collab_id))\n","\n","# check if apps exist; if not then create them\n","MCapp_navID = catalog.exists_in_collab_else_create(collab_id)\n","catalog.set_app_config(collab_id=collab_id, app_id=MCapp_navID, only_if_new=\"True\")\n","VFapp_navID = test_library.exists_in_collab_else_create(collab_id)\n","test_library.set_app_config(collab_id=collab_id, app_id=VFapp_navID, only_if_new=\"True\")\n","\n","print(\"\\n\\nLink to Model Catalog app:\")\n","print(\"https://collab.humanbrainproject.eu/#/collab/{}/nav/{}\".format(str(collab_id),str(MCapp_navID)))\n","print(\"\\nLink to Test Library app:\")\n","print(\"https://collab.humanbrainproject.eu/#/collab/{}/nav/{}\".format(str(collab_id),str(VFapp_navID)))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 4. Get information about the model from the HBP Model Catalog"]},{"metadata":{"collapsed":true,"trusted":true},"cell_type":"code","source":["from hbp_validation_framework import ModelCatalog\n","catalog = ModelCatalog()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["pc_models = catalog.list_models(cell_type=\"Purkinje cell\")\n","len(pc_models)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["for model in pc_models:\n","    if \"raw_data\" in model:\n","        model.pop(\"raw_data\")\n","print(pc_models[0])"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"collapsed":true},"cell_type":"code","source":["df = pd.DataFrame.from_dict(json_normalize(pc_models), orient='columns')\n","df"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["A model should have an attribute `model_uuid` that uniquely identifies it in the Model Catalog. The Purkinje cell model we're validating here is already registered in the catalog. \n","If you want to upload the validation test results for your own model to the Validation service,\n","you will first have to register your model using the Model Catalog app (see left-hand menu, or link above), or using the Python client. \n","\n","A model may contain multiple model instances. Each instance defines a particular version (identified by the attribute `model_version`) of a model by specifying the location of the source code for the model. A model may have multiple versions (model instances) which could vary, for example, in values of their biophysical parameters. Improvements and updates to a model would be considered as different versions (instances) of that particular model.\n","\n","For more information, see the [documentation](http://hbp-validation-client.readthedocs.io/)."]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["# model_uuid has been specified in model source code; hence commented out here\n","pc.model_uuid = \"a26248a9-6bbd-4950-99d5-2b9ac95505c1\"\n","\n","# sciunit provides models the ability to determines its version from Git\n","pc.model_version = pc.version"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["model_info = catalog.get_model(pc.model_uuid)\n","markdown(model_info[\"description\"])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 5. Find validation tests for Purkinje cell models"]},{"metadata":{"collapsed":true,"trusted":true},"cell_type":"code","source":["from hbp_validation_framework import TestLibrary\n","test_library = TestLibrary()"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true},"cell_type":"code","source":["tests = test_library.list_tests(cell_type=\"Purkinje Cell\")"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["for test in tests:\n","    print(\"{} ({})\".format(test[\"name\"], test[\"alias\"]))\n","print(\"Note: the list above is in the form `test_name (test_alias)`\")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["__Note:__ The `alias` attribute of a test is an (optional) unique human-readable identifier that can be assigned to a test. This makes it easier to refer to a test, rather than using the `test_uuid`. The latter is mandatory for every test and can be used to specify/identify tests."]},{"metadata":{},"cell_type":"markdown","source":["### 5.1 Load the test of interest\n","\n","Validation tests are implemented as Python classes. To load the test, we need to choose the version we want. First, we can get a list of versions:"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["test_library.list_test_instances(alias=\"PCSpontaneousFiringTest\")\n","# test_library.list_test_instances(alias=\"PCComplexBurstingTest\")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Now we can get an instance of the Python class that implements the test, initialized with the experimental reference data. "]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["test = test_library.get_validation_test(alias=\"PCSpontaneousFiringTest\", version=\"0.1.dev\")\n","# test = test_library.get_validation_test(alias=\"PCComplexBurstingTest\", version=\"0.1.dev\")"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["print(test.description)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 5.2 Look at the test data"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["test.observation"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 6. Run the validation test\n","\n","Now we can run the test on the Purkinje neuron model:"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["score = test.judge(pc)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["score.score"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["But what does this score mean? Is it a good or bad result? To find out, we can check the score's description:"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["score.description"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["print(score._description)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["We can remind ourselves of the experimental data (the \"observation\") we are validating against:"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["score.observation"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["and see more detail of the simulation results (the \"prediction\")"]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["score.prediction"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 6.1 Save the validation result to the result database\n","\n","Below we first extract the `collab_id`. Every test result in the Validation Framework is registered with a `project` attribute. This corresponds to the ID of the Collab in which the test was executed. The _Storage_ of this Collab would be utilized for storing and test related files."]},{"metadata":{"collapsed":true,"trusted":true},"cell_type":"code","source":["def get_collab_id():\n","    \"\"\"Workaround to get the collab id from within a notebook\"\"\"\n","    import inspect\n","    import re\n","    \n","    somecode = inspect.getsource(get_collab_storage_path)\n","    match = re.search(r'collab_id=(?P<collab_id>\\d+)', somecode)\n","    return match.groupdict()['collab_id']"],"execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":true},"cell_type":"code","source":["collab_id = get_collab_id()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["from hbp_validation_framework.datastores import CollabDataStore\n","from datetime import datetime\n","\n","timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","folder_name = \"results_{}_{}_{}\".format(pc.name, pc.model_uuid[:8], timestamp)\n","collab_storage = CollabDataStore(base_folder=folder_name)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":["response = test_library.register_result(score, data_store=collab_storage, project=collab_id)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 7. Browse the result database\n","\n","In the left-hand menu, you should see a menu item \"Validation Framework\" (if not, please refresh the page so that the newly added apps are visible).\n","Right-click on this to open in a separate tab. \n","You will now see a list of all registered models and validation tests.\n","In the \"Select cell type\" dropdown, choose \"Purkinje cell\" to only show models of this cell type\n","and tests for such models.\n","\n","\n","Now click on \"PCSpontaneousFiringTest\".\n","This shows a description of the test. \n","You can click on \"Version\" to find the code for the test, \n","on \"Results\" to see the scores for each time this test has been run,\n","and on \"Comments\" to see a discussion about this test and the associated data.\n",""]},{"metadata":{"trusted":true,"scrolled":true,"collapsed":true},"cell_type":"code","source":["print(\"Alternatively, you can click here to directly go the result that was currently registered:\")\n","print(\"https://collab.humanbrainproject.eu/#/collab/{}/nav/{}?state=result.{}\".format(str(collab_id),str(VFapp_navID), response))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## 8. Summary\n","\n","The steps shown in this notebook can be applied to any model and any test.\n","To recap, the general steps are as follows:\n","\n","- register your model, using the Model Catalog app\n","- on the computer where you will run the tests (or in a Collab notebook), install your model code, the test code, and the `hbp_validation_framework` Python package.\n","- using the `TestLibrary` client, download and instantiate a test.\n","- call `test.judge(model)`\n","- again using the `TestLibrary` client, upload the test results to the Validation service."]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}